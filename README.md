# twitter-scraper-lite

<img src="twitter-scraper-lite.svg" alt="twitter-scraper-lite logo" width="100px">

a super lightweight Twitter scraper

## prerequisites

to use this, you should be able to:

- write some python
- inspect a webpage

## install

`git clone` this repo directly, or `git submodule add` it to your existing repo

use python 3.7+

install some dependencies:

```bash
pip install tqdm termcolor selenium
```

the machine needs to have a version of chrome or chromium installed, ubuntu installation example:

```bash
sudo curl -sS -o - https://dl-ssl.google.com/linux/linux_signing_key.pub | sudo apt-key add
echo "deb http://dl.google.com/linux/chrome/deb/ stable main"  | sudo tee /etc/apt/sources.list.d/google-chrome.list
sudo apt-get -y update
sudo apt-get -y install google-chrome-stable
```

download the correct version of chromedriver from [here](https://chromedriver.chromium.org/downloads), unzip and put it in the same directory as `scrape.py`

## usage

see

```
python scrape.py -h
```

```
python parse.py -h
```


## overview

twitter's official API has the following drawbacks:

- require dev login
- rate limited

this solution uses selenium to scrape and parse the front end webpage of twitter, specifically the search. 

for each profile, `scrape.py` performs the following:

1. search tweets from that profile within a date range
1. scroll down repeatedly to load all results
1. extract the tweet id and raw html and save to disk
2. go to the next date range, repeat 

for each profile, `parse.py` performs the following:

1. pick one tweet id from the profile
2. load raw html from disk, parse to extract a dict of information
3. save to disk
4. go to the next tweet id, repeat

on disk, the data is saved as:

```
/
    meta/   # generated by scrape.py
        profile1.json
        profile2.json
    raw/    # generated by scrape.py
        tweet_id1.html
        tweet_id2.html
    parsed/ # generated by parse.py
        profile1.json
        profile2.json
```

## config

### `scrape.py`

configure `TWEET_SELECTOR` and `ID_SELECTOR` with the correct id selector, find this by inspecting the twitter's search page. [here's an example search page](https://twitter.com/search?q=from%3Abarackobama%20since%3A2020-06-14%20until%3A2020-07-01&src=typed_query&f=live). be sure to choose the one uniquely id each tweet box

configure `NO_RESULT_SELECTOR` with the box that shows "no search result". [here's an example search page](https://twitter.com/search?q=from%3Abarackobama%20since%3A2029-01-01&src=typed_query&f=live). this is used such that when there's not tweet found, and there's not "no result" on the page, we know we're rate limited by twitter and should wait for a while.

### `parse.py`

inspect each element you would like to parse from the raw html, and modify `parse_one_tweet`.


